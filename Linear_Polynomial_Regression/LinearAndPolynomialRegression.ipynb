{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "421076b7-b618-435b-8c58-fac0a4e42748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (3605, 25)\n",
      "Validation features shape: (902, 25)\n",
      "Test features shape: (500, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import ElasticNetCV, RidgeCV, LassoCV, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Custom transformer for clipping ---\n",
    "class PercentileClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Clips features based on training data percentiles.\"\"\"\n",
    "    def __init__(self, lower_percentile=1.0, upper_percentile=99.0):\n",
    "        self.lower_percentile = lower_percentile\n",
    "        self.upper_percentile = upper_percentile\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.lower_bounds_ = np.percentile(X, self.lower_percentile, axis=0)\n",
    "        self.upper_bounds_ = np.percentile(X, self.upper_percentile, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_clipped = np.clip(X, self.lower_bounds_, self.upper_bounds_)\n",
    "        return X_clipped\n",
    "\n",
    "# --- Feature Engineering Function ---\n",
    "def feature_engineering(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    df['Equipment_Volume'] = df['Equipment_Height'] * df['Equipment_Width']\n",
    "    #df['Equipment_Value_Log'] = np.log1p(df['Equipment_Value'])\n",
    "    \n",
    "    return df\n",
    "   \n",
    "\n",
    "# --- Load data ---\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test  = pd.read_csv('test.csv')\n",
    "\n",
    "# --- Extract target first ---\n",
    "# --- Keep target ---\n",
    "df_train = df_train[df_train['Transport_Cost'] >= 0]\n",
    "df_train['Log_Transport_Cost'] = np.log1p(df_train['Transport_Cost'])\n",
    "y_train_full = df_train['Log_Transport_Cost'] # Renamed to y_train_full for clarity\n",
    "\n",
    "# --- Apply feature engineering on full train/test (do NOT drop date/ID columns yet) ---\n",
    "df_train_fe= feature_engineering(df_train, is_train=True)\n",
    "df_test_fe = feature_engineering(df_test, is_train=False)\n",
    "\n",
    "# --- Drop non-feature columns AFTER feature engineering ---\n",
    "drop_cols_train = ['Transport_Cost', 'Log_Transport_Cost', 'Hospital_Id',  \n",
    "                   'Order_Placed_Date', 'Delivery_Date', 'Hospital_Location', 'Supplier_Name',\n",
    "                   'Equipment_Height', 'Equipment_Width'] \n",
    "drop_cols_test = ['Hospital_Id', 'Order_Placed_Date', 'Delivery_Date', 'Hospital_Location', 'Supplier_Name',\n",
    "                  'Equipment_Height', 'Equipment_Width']\n",
    "\n",
    "X_train_full = df_train_fe.drop(columns=[c for c in drop_cols_train if c in df_train_fe.columns])\n",
    "X_test       = df_test_fe.drop(columns=[c for c in drop_cols_test if c in df_test_fe.columns])\n",
    "\n",
    "# --- Feature lists ---\n",
    "numeric_features = [\n",
    "    'Supplier_Reliability', \n",
    "    'Base_Transport_Fee',\n",
    "    'Equipment_Volume', \n",
    "    'Equipment_Weight',\n",
    "    'Equipment_Value', \n",
    "]\n",
    "\n",
    "\n",
    "categorical_features = [\n",
    "    'Equipment_Type',\n",
    "    'CrossBorder_Shipping',\n",
    "    'Installation_Service', \n",
    "    'Transport_Method',\n",
    "    'Fragile_Equipment', \n",
    "    'Hospital_Info',\n",
    "    'Rural_Hospital'\n",
    "]\n",
    "\n",
    "# --- Preprocessing pipelines ---\n",
    "numeric_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    PercentileClipper(lower_percentile=1.0, upper_percentile=99.0),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "\n",
    "# --- Train/validation split ---\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# --- Fit preprocessor on training set, transform val/test ---\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed   = preprocessor.transform(X_val)\n",
    "\n",
    "# X_test is the DataFrame with the correct columns (non-features dropped)\n",
    "X_test_processed  = preprocessor.transform(X_test) \n",
    "\n",
    "print(f\"Training features shape: {X_train_processed.shape}\")\n",
    "print(f\"Validation features shape: {X_val_processed.shape}\")\n",
    "print(f\"Test features shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edffdbd-d316-4194-9a6d-045ed640d9a0",
   "metadata": {},
   "source": [
    "# Linear Regression without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84298ddd-5ca4-45a8-a62e-af47c22177a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Model 1: Normal Linear Regression ---\n",
      "Model 1 (Linear Regression) trained.\n",
      "\n",
      "--- Model 1 Evaluation ---\n",
      "Validation RMSE: $105,378.64\n",
      "Validation R-squared: 0.462\n",
      "Validation MAE: $12,486.827\n",
      "Validation RMSE (log-scale): 0.747\n",
      "Validation R-squared (log-scale): 0.774\n",
      "Validation MAE (log-scale): 0.472\n",
      "\n",
      "--- submission_linear_normal.csv created successfully! ---\n",
      "            Hospital_Id  Transport_Cost\n",
      "0          fffe33003400      611.057394\n",
      "1  fffe3700330036003600      281.620369\n",
      "2  fffe3300390038003400     3969.136283\n",
      "3      fffe310030003900      303.932761\n",
      "4  fffe3700330031003200      812.867667\n"
     ]
    }
   ],
   "source": [
    "######### linear regression without regularization #########\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# selectKBest features was tried but got better results without it so\n",
    "from sklearn.linear_model import LinearRegression  # <-- We import the normal one\n",
    "\n",
    "print(\"--- Starting Model 1: Normal Linear Regression ---\")\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Model 1 (Linear Regression) trained.\")\n",
    "\n",
    "# --- Evaluate Model 1 ---\n",
    "y_pred_log = lr_model.predict(X_val_processed)\n",
    "\n",
    "if np.any(y_pred_log > 700):\n",
    "    print(\"WARNING: Elastic Net produced an unstable (infinite) prediction. Model failed.\")\n",
    "else:\n",
    "    # Get predictions on the TRAINING data (log-scale) to calculate residuals\n",
    "    y_train_pred_log = lr_model.predict(X_train_processed)\n",
    "    # Calculate the log-scale residuals (errors)\n",
    "    train_residuals_log = y_train - y_train_pred_log\n",
    "\n",
    "    y_val_actual = np.expm1(y_val)\n",
    "    y_pred_actual = np.expm1(y_pred_log)\n",
    "    y_pred_actual_corrected = y_pred_actual\n",
    "    \n",
    "    print(\"\\n--- Model 1 Evaluation ---\")\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_actual, y_pred_actual_corrected))\n",
    "    r2 = r2_score(y_val_actual, y_pred_actual_corrected)\n",
    "    mae = mean_absolute_error(y_val_actual, y_pred_actual_corrected)\n",
    "\n",
    "    print(f\"Validation RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"Validation R-squared: {r2:.3f}\")\n",
    "    print(f\"Validation MAE: ${mae:,.3f}\")\n",
    "\n",
    "    # on log valeus\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_val, y_pred_log))\n",
    "    r2_log = r2_score(y_val, y_pred_log)\n",
    "    mae_log = mean_absolute_error(y_val, y_pred_log)\n",
    "    \n",
    "    print(f\"Validation RMSE (log-scale): {rmse_log:.3f}\")\n",
    "    print(f\"Validation R-squared (log-scale): {r2_log:.3f}\")\n",
    "    print(f\"Validation MAE (log-scale): {mae_log:.3f}\")\n",
    "\n",
    "    y_pred_log = lr_model.predict(X_test_processed)\n",
    "    y_pred_actual = np.expm1(y_pred_log)\n",
    "    \n",
    "    # Ensure all predictions are non-negative for submission\n",
    "    y_pred_actual = np.maximum(0, y_pred_actual) \n",
    "    \n",
    "    # The 'y_pred_actual_corrected' variable is now just the simple inverse transform, \n",
    "    # as with bias correction the result was worse \n",
    "    y_pred_actual_final = y_pred_actual \n",
    "\n",
    "    # --- Create submission file ---\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Hospital_Id': df_test['Hospital_Id'],\n",
    "        'Transport_Cost': y_pred_actual_final \n",
    "    })\n",
    "    submission_df.to_csv('submission_linear_normal.csv', index=False)\n",
    "    print(\"\\n--- submission_linear_normal.csv created successfully! ---\")\n",
    "    print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33554ea-be51-48a8-b37b-f109d9252647",
   "metadata": {},
   "source": [
    "# Linear Regression -- LASSO Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89d091e1-56ac-4314-b0bd-4bdb7ba6be24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 (Lasso) trained.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Model 2 Evaluation ---\n",
      "Validation RMSE: $105,082.14\n",
      "Validation R-squared: 0.465\n",
      "Validation MAE: $12,445.939\n",
      "Best Alpha selected by LassoCV: 0.00029470517025518097\n",
      "Total features: 25\n",
      "Features dropped (zero coefficients): 3\n",
      "Features retained: 22\n",
      "\n",
      "--- Log-Scale Evaluation (Model Fit) ---\n",
      "Validation RMSE (log-scale): 0.747\n",
      "Validation R-squared (log-scale): 0.774\n",
      "Validation MAE (log-scale): 0.472\n",
      "\n",
      "--- submission_lasso.csv created successfully! ---\n",
      "            Hospital_Id  Transport_Cost\n",
      "0          fffe33003400      611.455857\n",
      "1  fffe3700330036003600      282.464141\n",
      "2  fffe3300390038003400     3958.812378\n",
      "3      fffe310030003900      303.014406\n",
      "4  fffe3700330031003200      812.707942\n"
     ]
    }
   ],
   "source": [
    "# ---  Train Lasso Model ---\n",
    "# LassoCV will find the best alpha\n",
    "lasso_model = LassoCV(\n",
    "    alphas=np.logspace(-5, -1, 50), # 50 alphas between 10^-5 and 10^-1\n",
    "    cv=5,\n",
    "    max_iter=10000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lasso_model.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Model 2 (Lasso) trained.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Evaluate Model 2 ---\n",
    "y_pred_log = lasso_model.predict(X_val_processed)\n",
    "\n",
    "if np.any(y_pred_log > 700):\n",
    "    print(\"WARNING: Lasso produced an unstable (infinite) prediction. Model failed.\")\n",
    "else:\n",
    "    # Get predictions on the TRAINING data (log-scale) to calculate residuals\n",
    "    y_train_pred_log = lasso_model.predict(X_train_processed)\n",
    "    # Calculate the log-scale residuals (errors)\n",
    "    train_residuals_log = y_train - y_train_pred_log\n",
    "\n",
    "    y_val_actual = np.expm1(y_val)\n",
    "    y_pred_actual = np.expm1(y_pred_log)\n",
    "    # Set corrected = actual (no correction factor)\n",
    "    y_pred_actual_corrected = y_pred_actual \n",
    "\n",
    "    print(\"\\n--- Model 2 Evaluation ---\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_actual, y_pred_actual_corrected))\n",
    "    r2 = r2_score(y_val_actual, y_pred_actual_corrected)\n",
    "    mae = mean_absolute_error(y_val_actual, y_pred_actual_corrected)\n",
    "\n",
    "    print(f\"Validation RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"Validation R-squared: {r2:.3f}\")\n",
    "    print(f\"Validation MAE: ${mae:,.3f}\")\n",
    "    print(f\"Best Alpha selected by LassoCV: {lasso_model.alpha_}\")\n",
    "\n",
    "    # --- Count dropped (zero) coefficients ---\n",
    "    n_total_features = X_train_processed.shape[1]\n",
    "    n_zero_coeff = np.sum(lasso_model.coef_ == 0)\n",
    "    n_nonzero_coeff = n_total_features - n_zero_coeff\n",
    "    \n",
    "    print(f\"Total features: {n_total_features}\")\n",
    "    print(f\"Features dropped (zero coefficients): {n_zero_coeff}\")\n",
    "    print(f\"Features retained: {n_nonzero_coeff}\")\n",
    "\n",
    "    print(\"\\n--- Log-Scale Evaluation (Model Fit) ---\")\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_val, y_pred_log))\n",
    "    r2_log = r2_score(y_val, y_pred_log)\n",
    "    mae_log = mean_absolute_error(y_val, y_pred_log)\n",
    "\n",
    "    print(f\"Validation RMSE (log-scale): {rmse_log:.3f}\")\n",
    "    print(f\"Validation R-squared (log-scale): {r2_log:.3f}\")\n",
    "    print(f\"Validation MAE (log-scale): {mae_log:.3f}\")\n",
    "\n",
    "    # --- 3. Create Submission File (Lasso) ---\n",
    "    y_pred_log_test = lasso_model.predict(X_test_processed)\n",
    "    y_pred_actual_test = np.expm1(y_pred_log_test)\n",
    "    \n",
    "    # Ensure all predictions are non-negative for submission\n",
    "    y_pred_actual_test = np.maximum(0, y_pred_actual_test) \n",
    "    y_pred_actual_final = y_pred_actual_test \n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Hospital_Id': df_test['Hospital_Id'],\n",
    "        'Transport_Cost': y_pred_actual_final\n",
    "    })\n",
    "    submission_df.to_csv('submission_lasso.csv', index=False)\n",
    "    print(\"\\n--- submission_lasso.csv created successfully! ---\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cb006-7d2e-45e5-9635-164650d85ff7",
   "metadata": {},
   "source": [
    "# Linear Regression -- Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "403ef5da-7c19-497f-b49b-42f6bf7b7b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 (Ridge) trained.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Model 3 Evaluation ---\n",
      "Validation RMSE: $104,974.19\n",
      "Validation R-squared: 0.467\n",
      "Validation MAE: $12,434.654\n",
      "Best Alpha selected by RidgeCV: 6.25055192527397\n",
      "\n",
      "--- Log-Scale Evaluation (Model Fit) ---\n",
      "Validation RMSE (log-scale): 0.747\n",
      "Validation R-squared (log-scale): 0.774\n",
      "Validation MAE (log-scale): 0.472\n",
      "\n",
      "--- submission_ridge.csv created successfully! ---\n",
      "            Hospital_Id  Transport_Cost\n",
      "0          fffe33003400      613.231112\n",
      "1  fffe3700330036003600      283.283091\n",
      "2  fffe3300390038003400     3922.995097\n",
      "3      fffe310030003900      303.675635\n",
      "4  fffe3700330031003200      814.697890\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Train Ridge Model ---\n",
    "# RidgeCV will find the best alpha. Ridge is often more stable\n",
    "# and efficient, so we can test a wider range of alphas.\n",
    "ridge_model = RidgeCV(\n",
    "    alphas=np.logspace(-3, 3, 50), # 50 alphas between 10^-3 and 10^3\n",
    "    cv=5\n",
    ")\n",
    "ridge_model.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Model 3 (Ridge) trained.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Evaluate Model 3 ---\n",
    "y_pred_log = ridge_model.predict(X_val_processed)\n",
    "\n",
    "if np.any(y_pred_log > 700):\n",
    "    print(\"WARNING: Ridge produced an unstable (infinite) prediction. Model failed.\")\n",
    "else:\n",
    "    # Get predictions on the TRAINING data (log-scale) to calculate residuals\n",
    "    y_train_pred_log = ridge_model.predict(X_train_processed)\n",
    "    # Calculate the log-scale residuals (errors)\n",
    "    train_residuals_log = y_train - y_train_pred_log\n",
    "    \n",
    "    y_val_actual = np.expm1(y_val)\n",
    "    y_pred_actual = np.expm1(y_pred_log)\n",
    "    # Set corrected = actual (no correction factor)\n",
    "    y_pred_actual_corrected = y_pred_actual \n",
    "\n",
    "    print(\"\\n--- Model 3 Evaluation ---\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_actual, y_pred_actual_corrected))\n",
    "    r2 = r2_score(y_val_actual, y_pred_actual_corrected)\n",
    "    mae = mean_absolute_error(y_val_actual, y_pred_actual_corrected)\n",
    "\n",
    "    print(f\"Validation RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"Validation R-squared: {r2:.3f}\")\n",
    "    print(f\"Validation MAE: ${mae:,.3f}\")\n",
    "    print(f\"Best Alpha selected by RidgeCV: {ridge_model.alpha_}\")\n",
    "\n",
    "    print(\"\\n--- Log-Scale Evaluation (Model Fit) ---\")\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_val, y_pred_log))\n",
    "    r2_log = r2_score(y_val, y_pred_log)\n",
    "    mae_log = mean_absolute_error(y_val, y_pred_log)\n",
    "\n",
    "    print(f\"Validation RMSE (log-scale): {rmse_log:.3f}\")\n",
    "    print(f\"Validation R-squared (log-scale): {r2_log:.3f}\")\n",
    "    print(f\"Validation MAE (log-scale): {mae_log:.3f}\")\n",
    "\n",
    "    # --- Create Submission File ---\n",
    "    y_pred_log_test = ridge_model.predict(X_test_processed)\n",
    "    y_pred_actual_test = np.expm1(y_pred_log_test)\n",
    "    \n",
    "    # Ensure all predictions are non-negative for submission\n",
    "    y_pred_actual_test = np.maximum(0, y_pred_actual_test) \n",
    "    y_pred_actual_final = y_pred_actual_test \n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Hospital_Id': df_test['Hospital_Id'],\n",
    "        'Transport_Cost': y_pred_actual_final\n",
    "    })\n",
    "    submission_df.to_csv('submission_ridge.csv', index=False)\n",
    "    print(\"\\n--- submission_ridge.csv created successfully! ---\")\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694bf10-048b-4af0-b723-cb09e2a297a0",
   "metadata": {},
   "source": [
    "# Linear Regression -- Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "446fac33-ed6a-4813-8d2f-a1262cf59c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 (Elastic Net) trained.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Model 4 Evaluation ---\n",
      "Validation RMSE: $105,077.49\n",
      "Validation R-squared: 0.465\n",
      "Validation MAE: $12,445.386\n",
      "Best L1 Ratio selected by ElasticNetCV: 0.9\n",
      "Best Alpha selected by ElasticNetCV: 0.00032903445623126676\n",
      "\n",
      "--- Log-Scale Evaluation (Model Fit) ---\n",
      "Validation RMSE (log-scale): 0.747\n",
      "Validation R-squared (log-scale): 0.774\n",
      "Validation MAE (log-scale): 0.472\n",
      "\n",
      "--- submission_elastic.csv created successfully! ---\n",
      "            Hospital_Id  Transport_Cost\n",
      "0          fffe33003400      611.481893\n",
      "1  fffe3700330036003600      282.480102\n",
      "2  fffe3300390038003400     3957.603469\n",
      "3      fffe310030003900      302.990553\n",
      "4  fffe3700330031003200      812.987080\n"
     ]
    }
   ],
   "source": [
    "# --- Train Elastic Net Model ---\n",
    "# We give it a list of L1 ratios (the mix) and it will find the best alpha\n",
    "elastic_model = ElasticNetCV(\n",
    "    # Narrow the search around 1.0 (Lasso) since the previous model chose 1.0\n",
    "    l1_ratio=[.9, .95, .99, .999, 1.0], \n",
    "    alphas=np.logspace(-4, -1, 30), # Increase alpha search points\n",
    "    cv=5,\n",
    "    max_iter=10000, # Increased max_iter for stability\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "elastic_model.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Model 4 (Elastic Net) trained.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 8. Evaluate Model 4 ---\n",
    "y_pred_log = elastic_model.predict(X_val_processed)\n",
    "\n",
    "if np.any(y_pred_log > 700):\n",
    "    print(\"WARNING: Elastic Net produced an unstable (infinite) prediction. Model failed.\")\n",
    "else:\n",
    "    # Get predictions on the TRAINING data (log-scale) to calculate residuals\n",
    "    y_train_pred_log = elastic_model.predict(X_train_processed)\n",
    "    # Calculate the log-scale residuals (errors)\n",
    "    train_residuals_log = y_train - y_train_pred_log\n",
    "\n",
    "    y_val_actual = np.expm1(y_val)\n",
    "    y_pred_actual = np.expm1(y_pred_log)\n",
    "    y_pred_actual_corrected = y_pred_actual\n",
    "\n",
    "    print(\"\\n--- Model 4 Evaluation ---\")\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_actual, y_pred_actual_corrected))\n",
    "    r2 = r2_score(y_val_actual, y_pred_actual_corrected)\n",
    "    mae = mean_absolute_error(y_val_actual, y_pred_actual_corrected)\n",
    "\n",
    "    print(f\"Validation RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"Validation R-squared: {r2:.3f}\")\n",
    "    print(f\"Validation MAE: ${mae:,.3f}\")\n",
    "    print(f\"Best L1 Ratio selected by ElasticNetCV: {elastic_model.l1_ratio_}\")\n",
    "    print(f\"Best Alpha selected by ElasticNetCV: {elastic_model.alpha_}\")\n",
    "\n",
    "    print(\"\\n--- Log-Scale Evaluation (Model Fit) ---\")\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_val, y_pred_log))\n",
    "    r2_log = r2_score(y_val, y_pred_log)\n",
    "    mae_log = mean_absolute_error(y_val, y_pred_log)\n",
    "\n",
    "    print(f\"Validation RMSE (log-scale): {rmse_log:.3f}\")\n",
    "    print(f\"Validation R-squared (log-scale): {r2_log:.3f}\")\n",
    "    print(f\"Validation MAE (log-scale): {mae_log:.3f}\")\n",
    "\n",
    "    y_pred_log = elastic_model.predict(X_test_processed)\n",
    "    y_pred_actual = np.expm1(y_pred_log)\n",
    "    \n",
    "    # Ensure all predictions are non-negative for submission\n",
    "    y_pred_actual = np.maximum(0, y_pred_actual) \n",
    "    y_pred_actual_final = y_pred_actual \n",
    "    \n",
    "    # --- Create submission file ---\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Hospital_Id': df_test['Hospital_Id'],\n",
    "        'Transport_Cost': y_pred_actual_final \n",
    "    })\n",
    "    submission_df.to_csv('submission_elastic.csv', index=False)\n",
    "    print(\"\\n--- submission_elastic.csv created successfully! ---\")\n",
    "    print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c19cf3-e66a-4e04-95e3-53ed9020f7ee",
   "metadata": {},
   "source": [
    "# Polynomial Regression of degree 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05468fd5-9137-4978-aaa5-02bb72f42094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial features created. New shape: (3605, 350)\n",
      "Polynomial features scaled.\n",
      "Model 5 (Polynomial + Ridge) trained.\n",
      "\n",
      "--- Model 5 Evaluation (Actual Scale) ---\n",
      "Validation RMSE: $236,274.06\n",
      "Validation R-squared: -1.703\n",
      "Validation MAE: $24,188.17\n",
      "Best Alpha selected by RidgeCV: 100.0\n",
      "\n",
      "--- Model 5 Evaluation (Log Scale) ---\n",
      "Validation RMSE (log): 0.610\n",
      "Validation R² (log): 0.850\n",
      "Validation MAE (log): 0.351\n",
      "\n",
      "Average R² (5-fold CV): 0.8772245576593537\n",
      "\n",
      "--- submission_poly2.csv created successfully! ---\n",
      "            Hospital_Id  Transport_Cost\n",
      "0          fffe33003400      590.664047\n",
      "1  fffe3700330036003600      230.085863\n",
      "2  fffe3300390038003400     4236.898356\n",
      "3      fffe310030003900      241.965815\n",
      "4  fffe3700330031003200     1110.902280\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# --- 1. Polynomial Features (degree 2) ---\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit(X_train_processed)\n",
    "\n",
    "X_train_poly = poly.transform(X_train_processed)\n",
    "X_val_poly   = poly.transform(X_val_processed)\n",
    "X_test_poly  = poly.transform(X_test_processed)\n",
    "\n",
    "print(f\"Polynomial features created. New shape: {X_train_poly.shape}\")\n",
    "\n",
    "# --- 2. Re-Scale the Polynomial Features ---\n",
    "scaler_poly = StandardScaler()\n",
    "X_train_poly_scaled = scaler_poly.fit_transform(X_train_poly)\n",
    "X_val_poly_scaled   = scaler_poly.transform(X_val_poly)\n",
    "X_test_poly_scaled  = scaler_poly.transform(X_test_poly)\n",
    "\n",
    "print(\"Polynomial features scaled.\")\n",
    "\n",
    "# --- 3. Train Ridge (L2) Model on Poly Features ---\n",
    "poly_ridge_model = RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0], cv=5)\n",
    "poly_ridge_model.fit(X_train_poly_scaled, y_train)\n",
    "\n",
    "print(\"Model 5 (Polynomial + Ridge) trained.\")\n",
    "\n",
    "# --- 4. Evaluate on Validation Set ---\n",
    "y_pred_log = poly_ridge_model.predict(X_val_poly_scaled)\n",
    "\n",
    "if np.any(np.isnan(y_pred_log)) or np.any(np.isinf(y_pred_log)):\n",
    "    print(\"WARNING: Polynomial model produced unstable predictions.\")\n",
    "else:\n",
    "    # Inverse-transform (log → actual)\n",
    "    y_val_actual = np.expm1(y_val)\n",
    "    y_pred_actual = np.expm1(y_pred_log)\n",
    "\n",
    "    # Metrics on actual values\n",
    "    rmse = np.sqrt(mean_squared_error(y_val_actual, y_pred_actual))\n",
    "    r2 = r2_score(y_val_actual, y_pred_actual)\n",
    "    mae = mean_absolute_error(y_val_actual, y_pred_actual)\n",
    "\n",
    "    print(\"\\n--- Model 5 Evaluation (Actual Scale) ---\")\n",
    "    print(f\"Validation RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"Validation R-squared: {r2:.3f}\")\n",
    "    print(f\"Validation MAE: ${mae:,.2f}\")\n",
    "    print(f\"Best Alpha selected by RidgeCV: {poly_ridge_model.alpha_}\")\n",
    "\n",
    "    # Metrics on log scale\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_val, y_pred_log))\n",
    "    r2_log = r2_score(y_val, y_pred_log)\n",
    "    mae_log = mean_absolute_error(y_val, y_pred_log)\n",
    "\n",
    "    print(\"\\n--- Model 5 Evaluation (Log Scale) ---\")\n",
    "    print(f\"Validation RMSE (log): {rmse_log:.3f}\")\n",
    "    print(f\"Validation R² (log): {r2_log:.3f}\")\n",
    "    print(f\"Validation MAE (log): {mae_log:.3f}\")\n",
    "\n",
    "    # Cross-validation on training data\n",
    "    scores = cross_val_score(poly_ridge_model, X_train_poly_scaled, y_train, scoring='r2', cv=5)\n",
    "    print(\"\\nAverage R² (5-fold CV):\", scores.mean())\n",
    "\n",
    "    # --- 5. Predict on Test Data ---\n",
    "    y_pred_log_test = poly_ridge_model.predict(X_test_poly_scaled)\n",
    "    y_pred_actual_test = np.expm1(y_pred_log_test)\n",
    "\n",
    "    # Retrieve Hospital_Id from df_test\n",
    "    test_ids = df_test[\"Hospital_Id\"]\n",
    "\n",
    "    # Create submission file\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Hospital_Id': test_ids,\n",
    "        'Transport_Cost': y_pred_actual_test\n",
    "    })\n",
    "\n",
    "    submission_df.to_csv('submission_poly2.csv', index=False)\n",
    "    print(\"\\n--- submission_poly2.csv created successfully! ---\")\n",
    "    print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000faa8f-22dc-4060-8a96-df6fdb91c268",
   "metadata": {},
   "source": [
    "# for polynomial of degree 3:\n",
    "# By creating so many extra features, the model became so complex and unstable that its predictions on new data are completely nonsensical, resulting in a gigantic error. It is better to avoid training it and stick to max, a polynomial of degree 2 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
