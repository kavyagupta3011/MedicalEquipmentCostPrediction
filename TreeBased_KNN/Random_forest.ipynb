{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb7d20b-6d0a-42ad-a97b-58a6fff554f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying alternative path...\n",
      "Original train data shape: (5000, 20)\n",
      "Original test data shape: (500, 19)\n",
      "Found 493 rows with non-positive cost. Setting them to 0.\n",
      "Combined data shape for preprocessing: (5500, 20)\n",
      "Starting feature engineering...\n",
      "Feature engineering complete.\n",
      "Building preprocessing pipeline...\n",
      "Final shapes: X=(5000, 26), y=(5000,), X_test=(500, 26)\n",
      "\n",
      "--- Starting Model Tuning for Random Forest ---\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'n_estimators': 800, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True}\n",
      "\n",
      "Random Forest RMSE (on validation): 41714.88\n",
      "Random Forest MSE (on validation): 1740130982.78\n",
      "Retraining Random Forest on full training data...\n",
      "\n",
      "--- DONE ---\n",
      "Submission file 'submission_RANDOM_FOREST.csv' created successfully.\n",
      "            Hospital_Id  Transport_Cost\n",
      "0          fffe33003400      141.927769\n",
      "1  fffe3700330036003600      125.636713\n",
      "2  fffe3300390038003400      817.813366\n",
      "3      fffe310030003900      136.853104\n",
      "4  fffe3700330031003200      514.328197\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "#Load Data\n",
    "try:\n",
    "    train_df_raw = pd.read_csv(\"medical_cost_prediction/train.csv\")\n",
    "    test_df_raw = pd.read_csv(\"medical_cost_prediction/test.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Trying alternative path...\")\n",
    "    try:\n",
    "        train_df_raw = pd.read_csv(\"trainvad.csv\")\n",
    "        test_df_raw = pd.read_csv(\"test.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not find train.csv or test.csv. {e}\")\n",
    "        raise\n",
    "\n",
    "print(f\"Original train data shape: {train_df_raw.shape}\")\n",
    "print(f\"Original test data shape: {test_df_raw.shape}\")\n",
    "\n",
    "test_hospital_ids = test_df_raw['Hospital_Id']\n",
    "\n",
    "#Clean Target Variable & Log Transform\n",
    "target = train_df_raw['Transport_Cost'].copy()\n",
    "invalid_cost_indices = target[target <= 0].index\n",
    "print(f\"Found {len(invalid_cost_indices)} rows with non-positive cost. Setting them to 0.\")\n",
    "target.loc[invalid_cost_indices] = 0\n",
    "target_log = np.log1p(target)\n",
    "\n",
    "train_df_processed = train_df_raw.drop('Transport_Cost', axis=1)\n",
    "train_df_processed['source'] = 'train'\n",
    "test_df_raw['source'] = 'test'\n",
    "df = pd.concat([train_df_processed, test_df_raw], ignore_index=True)\n",
    "print(f\"Combined data shape for preprocessing: {df.shape}\")\n",
    "\n",
    "#Feature Engineering\n",
    "missing_cols = [\n",
    "    'Supplier_Reliability',\n",
    "    'Equipment_Height',\n",
    "    'Equipment_Width',\n",
    "    'Equipment_Weight',\n",
    "    'Equipment_Type',\n",
    "    'Transport_Method',\n",
    "    'Rural_Hospital'\n",
    "]\n",
    "\n",
    "def preprocess_features(df_to_process):\n",
    "    print(\"Starting feature engineering...\")\n",
    "    df_processed = df_to_process.copy()\n",
    "    df_processed = df_processed.drop(['Supplier_Name'], axis=1)\n",
    "    \n",
    "    #Date Features\n",
    "    df_processed['Order_Placed_Date'] = pd.to_datetime(df_processed['Order_Placed_Date'])\n",
    "    df_processed['Delivery_Date'] = pd.to_datetime(df_processed['Delivery_Date'])\n",
    "    df_processed['Delivery_Time_Days'] = (df_processed['Delivery_Date'] - df_processed['Order_Placed_Date']).dt.days.clip(lower=0)\n",
    "    df_processed = df_processed.drop(['Order_Placed_Date', 'Delivery_Date'], axis=1)\n",
    "\n",
    "    #Location Features\n",
    "    df_processed['Hospital_State'] = df_processed['Hospital_Location'].str.split(',').str[1].str.strip().str.split(' ').str[0]\n",
    "    df_processed['Hospital_State'] = df_processed['Hospital_State'].fillna('Unknown')\n",
    "    df_processed = df_processed.drop('Hospital_Location', axis=1)\n",
    "\n",
    "    #Binary Features\n",
    "    binary_cols = ['CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service', \n",
    "                   'Fragile_Equipment', 'Rural_Hospital', 'Hospital_Info']\n",
    "    for col in binary_cols:\n",
    "        df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "\n",
    "    #Interaction Features\n",
    "    df_processed['Equipment_Height'] = df_processed['Equipment_Height'].fillna(1)\n",
    "    df_processed['Equipment_Width'] = df_processed['Equipment_Width'].fillna(1)\n",
    "    df_processed['Equipment_Weight'] = df_processed['Equipment_Weight'].fillna(0)\n",
    "    df_processed['Equipment_Value'] = df_processed['Equipment_Value'].fillna(0)\n",
    "\n",
    "    df_processed['Equipment_Area'] = df_processed['Equipment_Height'] * df_processed['Equipment_Width']\n",
    "    df_processed['Value_Density'] = df_processed['Equipment_Value'] / (df_processed['Equipment_Weight'] + 1e-6)\n",
    "    df_processed[\"Value_per_Height\"] = df_processed[\"Equipment_Value\"] / (df_processed[\"Equipment_Height\"] + 1e-6)\n",
    "    df_processed[\"Value_per_Width\"] = df_processed[\"Equipment_Value\"] / (df_processed[\"Equipment_Width\"] + 1e-6)\n",
    "    df_processed[\"Weight_per_Area\"] = df_processed[\"Equipment_Weight\"] / (df_processed[\"Equipment_Area\"] + 1e-6)\n",
    "    df_processed[\"Cost_per_Day\"] = df_processed[\"Base_Transport_Fee\"] / (df_processed[\"Delivery_Time_Days\"] + 1)\n",
    "    df_processed[\"Value_per_Area\"] = df_processed[\"Equipment_Value\"] / (df_processed[\"Equipment_Area\"] + 1e-6)\n",
    "\n",
    "    print(\"Feature engineering complete.\")\n",
    "    return df_processed\n",
    "\n",
    "df_featured = preprocess_features(df)\n",
    "\n",
    "#Preprocessing Pipeline\n",
    "print(\"Building preprocessing pipeline...\")\n",
    "\n",
    "numeric_features = ['Supplier_Reliability', \"Cost_per_Day\"]\n",
    "skewed_features = ['Equipment_Value', 'Base_Transport_Fee', 'Value_Density',\n",
    "                   'Equipment_Width', 'Equipment_Height', 'Equipment_Area',\n",
    "                   \"Value_per_Area\", \"Value_per_Height\", \"Value_per_Width\", \"Weight_per_Area\"]\n",
    "categorical_features = ['Equipment_Type', 'Transport_Method']\n",
    "binary_features = ['Fragile_Equipment', 'Rural_Hospital', 'Hospital_Info']\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True))\n",
    "])\n",
    "\n",
    "skewed_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('log_transform', FunctionTransformer(np.log1p, validate=False))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('skew', skewed_pipeline, skewed_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        ('binary', 'passthrough', binary_features)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "#Apply Preprocessing\n",
    "df_to_transform = df_featured.drop(['Hospital_Id', 'source'], axis=1)\n",
    "train_mask = df_featured['source'] == 'train'\n",
    "preprocessor.fit(df_to_transform[train_mask])\n",
    "df_final = preprocessor.transform(df_to_transform)\n",
    "\n",
    "train_mask_numpy = train_mask.values\n",
    "X = df_final[train_mask_numpy]\n",
    "X_test = df_final[~train_mask_numpy]\n",
    "y = target_log.reset_index(drop=True)\n",
    "\n",
    "print(f\"Final shapes: X={X.shape}, y={y.shape}, X_test={X_test.shape}\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Random Forest Model\n",
    "print(\"\\n--- Starting Model Tuning for Random Forest ---\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400, 600, 800],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "print(f\"Best parameters: {search.best_params_}\")\n",
    "\n",
    "#Evaluate on Validation Set\n",
    "y_pred_log = best_model.predict(X_val)\n",
    "y_pred_actual = np.expm1(y_pred_log)\n",
    "y_val_actual = np.expm1(y_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_actual, y_pred_actual))\n",
    "mse = mean_squared_error(y_val_actual, y_pred_actual)\n",
    "print(f\"\\nRandom Forest RMSE (on validation): {rmse:.2f}\")\n",
    "print(f\"Random Forest MSE (on validation): {mse:.2f}\")\n",
    "\n",
    "#Retrain on Full Data\n",
    "print(\"Retraining Random Forest on full training data...\")\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# --- 10. Predict on Test Data ---\n",
    "test_pred_log = best_model.predict(X_test)\n",
    "test_pred_actual = np.expm1(test_pred_log)\n",
    "test_pred_actual[test_pred_actual < 0] = 0  # Safety clip\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'Hospital_Id': test_hospital_ids,\n",
    "    'Transport_Cost': test_pred_actual\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission_RANDOM_FOREST.csv', index=False)\n",
    "\n",
    "print(\"\\n--- DONE ---\")\n",
    "print(\"Submission file 'submission_RANDOM_FOREST.csv' created successfully.\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c29f7c-d25a-41e0-9f05-4803697d0900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
