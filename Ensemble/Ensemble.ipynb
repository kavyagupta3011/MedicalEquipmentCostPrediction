{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acef05b6-f14f-4a47-8078-8b9921340178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the full ML pipeline (Strategy: v22 - Replicate v16 Features + Ensemble)...\n",
      "Original train data shape: (5000, 20)\n",
      "Original test data shape: (500, 19)\n",
      "Found 493 rows with non-positive cost. Setting them to 0.\n",
      "Combined data shape for preprocessing: (5500, 20)\n",
      "Starting feature engineering (v16 style)...\n",
      "Feature engineering complete.\n",
      "\n",
      "--- Building v16 'Accidentally Correct' pipeline ---\n",
      "Fitting final preprocessor...\n",
      "Extracting final feature names...\n",
      "Total features for training: 26\n",
      "Final shapes: X_df=(5000, 26), y=(5000,), X_test_df=(500, 26)\n",
      "\n",
      "--- Starting 10-Fold Ensemble Training (XGB + LGBM) ---\n",
      "--- Fold 1/10 ---\n",
      "--- Fold 2/10 ---\n",
      "--- Fold 3/10 ---\n",
      "--- Fold 4/10 ---\n",
      "--- Fold 5/10 ---\n",
      "--- Fold 6/10 ---\n",
      "--- Fold 7/10 ---\n",
      "--- Fold 8/10 ---\n",
      "--- Fold 9/10 ---\n",
      "--- Fold 10/10 ---\n",
      "\n",
      "--- Validation Results (Converted to Actual Cost) ---\n",
      "XGBoost OOF MSE: 58486291445.48\n",
      "LGBM OOF MSE:    58262372788.69\n",
      "BLEND OOF MSE:   58243011266.16\n",
      "Creating final submission file...\n",
      "\n",
      "--- DONE ---\n",
      "Submission file 'submission_v22_ensemble.csv' created successfully.\n",
      "            Hospital_Id  Transport_Cost\n",
      "0          fffe33003400      174.952706\n",
      "1  fffe3700330036003600      158.551587\n",
      "2  fffe3300390038003400     1001.511077\n",
      "3      fffe310030003900      144.577249\n",
      "4  fffe3700330031003200      567.131770\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb # <-- Import LightGBM\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"Starting the full ML pipeline (Strategy: v22 - Replicate v16 Features + Ensemble)...\")\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    train_df_raw = pd.read_csv(\"train.csv\")\n",
    "    test_df_raw = pd.read_csv(\"test.csv\")\n",
    "    sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: Could not find data files. {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"Original train data shape: {train_df_raw.shape}\")\n",
    "print(f\"Original test data shape: {test_df_raw.shape}\")\n",
    "\n",
    "test_hospital_ids = test_df_raw['Hospital_Id']\n",
    "\n",
    "# --- 2. Clean Target Variable ---\n",
    "target = train_df_raw['Transport_Cost'].copy()\n",
    "invalid_cost_indices = target[target <= 0].index\n",
    "print(f\"Found {len(invalid_cost_indices)} rows with non-positive cost. Setting them to 0.\")\n",
    "target.loc[invalid_cost_indices] = 0\n",
    "y_log = np.log1p(target) # We train on log-transformed target\n",
    "\n",
    "# Combine train and test for consistent preprocessing\n",
    "train_df_processed = train_df_raw.drop('Transport_Cost', axis=1)\n",
    "train_df_processed['source'] = 'train'\n",
    "test_df_raw['source'] = 'test'\n",
    "df = pd.concat([train_df_processed, test_df_raw], ignore_index=True)\n",
    "print(f\"Combined data shape for preprocessing: {df.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. Feature Engineering (Same as v16) ---\n",
    "# We create all features, even the ones we will drop, \n",
    "# because the kept features ('Cost_per_Day') might depend on them.\n",
    "missing_cols = [\n",
    "    'Supplier_Reliability', 'Equipment_Height', 'Equipment_Width', 'Equipment_Weight',\n",
    "    'Equipment_Type', 'Transport_Method', 'Rural_Hospital'\n",
    "]\n",
    "\n",
    "def preprocess_features(df_to_process):\n",
    "    print(\"Starting feature engineering (v16 style)...\")\n",
    "    df_processed = df_to_process.copy()\n",
    "    df_processed = df_processed.drop(['Supplier_Name'], axis=1)\n",
    "\n",
    "    # Missing value indicators (will be dropped by ColTransformer)\n",
    "    for col in missing_cols:\n",
    "        df_processed[col + '_Is_Missing'] = df_processed[col].isnull().astype(int)\n",
    "\n",
    "    # Date features\n",
    "    df_processed['Order_Placed_Date'] = pd.to_datetime(df_processed['Order_Placed_Date'], errors='coerce')\n",
    "    df_processed['Delivery_Date'] = pd.to_datetime(df_processed['Delivery_Date'], errors='coerce')\n",
    "    df_processed['Delivery_Time_Days'] = (df_processed['Delivery_Date'] - df_processed['Order_Placed_Date']).dt.days\n",
    "    df_processed['Delivery_Time_Days'] = df_processed['Delivery_Time_Days'].fillna(df_processed['Delivery_Time_Days'].median()).clip(lower=0)\n",
    "    df_processed = df_processed.drop(['Order_Placed_Date', 'Delivery_Date'], axis=1)\n",
    "\n",
    "    # Location features (will be dropped by ColTransformer)\n",
    "    df_processed['Hospital_State'] = df_processed['Hospital_Location'].str.split(',').str[1].str.strip().str.split(' ').str[0]\n",
    "    df_processed['Hospital_State'] = df_processed['Hospital_State'].fillna('Unknown')\n",
    "    df_processed = df_processed.drop('Hospital_Location', axis=1)\n",
    "\n",
    "    # Binary features\n",
    "    binary_cols = ['CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service',  \n",
    "                   'Fragile_Equipment', 'Rural_Hospital','Hospital_Info']\n",
    "    for col in binary_cols:\n",
    "        df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "\n",
    "    # Fill numeric\n",
    "    df_processed['Equipment_Height'] = df_processed['Equipment_Height'].fillna(1)\n",
    "    df_processed['Equipment_Width'] = df_processed['Equipment_Width'].fillna(1)\n",
    "    df_processed['Equipment_Weight'] = df_processed['Equipment_Weight'].fillna(0)\n",
    "    df_processed['Equipment_Value'] = df_processed['Equipment_Value'].fillna(0)\n",
    "\n",
    "    # Derived/interaction features (v16 style)\n",
    "    df_processed['Equipment_Area'] = df_processed['Equipment_Height'] * df_processed['Equipment_Width']\n",
    "    df_processed['Value_Density'] = df_processed['Equipment_Value'] / (df_processed['Equipment_Weight'] + 1e-6)\n",
    "    df_processed['Value_per_Height'] = df_processed['Equipment_Value'] / (df_processed['Equipment_Height'] + 1e-6)\n",
    "    df_processed['Value_per_Width'] = df_processed['Equipment_Value'] / (df_processed['Equipment_Width'] + 1e-6)\n",
    "    df_processed['Weight_per_Area'] = df_processed['Equipment_Weight'] / (df_processed['Equipment_Area'] + 1e-6)\n",
    "    df_processed['Cost_per_Day'] = df_processed['Base_Transport_Fee'] / (df_processed['Delivery_Time_Days'] + 1)\n",
    "    df_processed['Value_per_Area'] = df_processed['Equipment_Value'] / (df_processed['Equipment_Area'] + 1e-6)\n",
    "\n",
    "    print(\"Feature engineering complete.\")\n",
    "    return df_processed\n",
    "\n",
    "df_featured = preprocess_features(df)\n",
    "\n",
    "# --- 4. Preprocessing Pipeline (EXACTLY as in v16) ---\n",
    "print(\"\\n--- Building v16 'Accidentally Correct' pipeline ---\")\n",
    "\n",
    "# These are the *only* features v16 used.\n",
    "numeric_features = ['Supplier_Reliability', \"Cost_per_Day\"]\n",
    "skewed_features = [\n",
    "    'Equipment_Value', 'Base_Transport_Fee', 'Value_Density', 'Equipment_Width', 'Equipment_Height',\n",
    "    'Equipment_Area', \"Value_per_Area\", \"Value_per_Height\", \"Value_per_Width\", \"Weight_per_Area\"\n",
    "]\n",
    "categorical_features = ['Equipment_Type', 'Transport_Method']\n",
    "binary_features = ['Fragile_Equipment', 'Rural_Hospital', 'Hospital_Info']\n",
    "\n",
    "# Build the pipelines\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "skewed_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('log_transform', FunctionTransformer(np.log1p, validate=False, feature_names_out=\"one-to-one\")),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('skew', skewed_pipeline, skewed_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        ('binary', 'passthrough', binary_features)\n",
    "    ],\n",
    "    remainder='drop', # This is the \"magic\" part that drops all other features\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "# --- 5. Apply Final Preprocessing ---\n",
    "df_to_transform = df_featured.drop(['Hospital_Id', 'source'], axis=1)\n",
    "train_mask = (df_featured['source'] == 'train').values\n",
    "\n",
    "print(\"Fitting final preprocessor...\")\n",
    "preprocessor.fit(df_to_transform[train_mask])\n",
    "\n",
    "print(\"Extracting final feature names...\")\n",
    "num_cols = list(preprocessor.named_transformers_['num'].get_feature_names_out()) if numeric_features else []\n",
    "skew_cols = list(preprocessor.named_transformers_['skew'].get_feature_names_out()) if skewed_features else []\n",
    "cat_cols = list(preprocessor.named_transformers_['cat'].get_feature_names_out()) if categorical_features else []\n",
    "bin_cols = binary_features\n",
    "final_feature_names = num_cols + skew_cols + cat_cols + bin_cols\n",
    "final_feature_names = [re.sub(r'[^A-Za-z0-9_]+', '', col) for col in final_feature_names]\n",
    "print(f\"Total features for training: {len(final_feature_names)}\")\n",
    "\n",
    "df_final = preprocessor.transform(df_to_transform)\n",
    "X = df_final[train_mask]\n",
    "X_test = df_final[~train_mask]\n",
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Convert to standard DataFrame (data is dense)\n",
    "X_df = pd.DataFrame(X, columns=final_feature_names)\n",
    "X_test_df = pd.DataFrame(X_test, columns=final_feature_names)\n",
    "\n",
    "y = y_log.reset_index(drop=True) # Our target is y_log\n",
    "\n",
    "print(f\"Final shapes: X_df={X_df.shape}, y={y.shape}, X_test_df={X_test_df.shape}\")\n",
    "\n",
    "# --- 6. Model Training (10-Fold Ensemble) ---\n",
    "print(\"\\n--- Starting 10-Fold Ensemble Training (XGB + LGBM) ---\")\n",
    "\n",
    "# Use robust parameters for both models\n",
    "# Use robust parameters for both models\n",
    "xgb_params = {\n",
    "    'learning_rate': 0.03, 'n_estimators': 1000, 'max_depth': 4,\n",
    "    'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 1,\n",
    "    'min_child_weight': 5, 'objective': 'reg:squarederror', 'tree_method': 'hist',\n",
    "    'random_state': 42, 'n_jobs': -1,\n",
    "    'early_stopping_rounds': 50  # <-- ADD THE PARAMETER HERE\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate': 0.03, 'n_estimators': 1000, 'max_depth': 4,\n",
    "    'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 1,\n",
    "    'min_child_weight': 5, 'objective': 'regression_l2', # L2 is MSE\n",
    "    'random_state': 42, 'n_jobs': -1, 'verbose': -1\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store out-of-fold predictions\n",
    "oof_preds_xgb = np.zeros(X_df.shape[0])\n",
    "oof_preds_lgbm = np.zeros(X_df.shape[0])\n",
    "# Arrays to store test predictions\n",
    "test_preds_xgb = np.zeros(X_test_df.shape[0])\n",
    "test_preds_lgbm = np.zeros(X_test_df.shape[0])\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_df, y)):\n",
    "    print(f\"--- Fold {fold+1}/10 ---\")\n",
    "    X_train, X_val = X_df.iloc[train_index], X_df.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # --- XGBoost ---\n",
    "    # --- XGBoost ---\n",
    "    xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False) # <-- REMOVED FROM HERE\n",
    "    oof_preds_xgb[val_index] = xgb_model.predict(X_val)\n",
    "    test_preds_xgb += xgb_model.predict(X_test_df) / kf.n_splits\n",
    "    \n",
    "    # --- LightGBM ---\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    oof_preds_lgbm[val_index] = lgb_model.predict(X_val)\n",
    "    test_preds_lgbm += lgb_model.predict(X_test_df) / kf.n_splits\n",
    "\n",
    "# --- 7. Evaluate OOF Predictions ---\n",
    "print(\"\\n--- Validation Results (Converted to Actual Cost) ---\")\n",
    "y_actual_oof = np.expm1(y) # The true, non-log-transformed costs\n",
    "\n",
    "# Convert OOF (log) predictions to actual cost\n",
    "y_pred_actual_xgb = np.expm1(oof_preds_xgb)\n",
    "y_pred_actual_lgbm = np.expm1(oof_preds_lgbm)\n",
    "\n",
    "# Create the blended prediction\n",
    "y_pred_actual_blend = 0.5 * y_pred_actual_xgb + 0.5 * y_pred_actual_lgbm\n",
    "\n",
    "# Clip negatives\n",
    "y_pred_actual_xgb[y_pred_actual_xgb < 0] = 0\n",
    "y_pred_actual_lgbm[y_pred_actual_lgbm < 0] = 0\n",
    "y_pred_actual_blend[y_pred_actual_blend < 0] = 0\n",
    "\n",
    "# Calculate MSE for each model and the blend\n",
    "mse_xgb = mean_squared_error(y_actual_oof, y_pred_actual_xgb)\n",
    "mse_lgbm = mean_squared_error(y_actual_oof, y_pred_actual_lgbm)\n",
    "mse_blend = mean_squared_error(y_actual_oof, y_pred_actual_blend)\n",
    "\n",
    "print(f\"XGBoost OOF MSE: {mse_xgb:.2f}\")\n",
    "print(f\"LGBM OOF MSE:    {mse_lgbm:.2f}\")\n",
    "print(f\"BLEND OOF MSE:   {mse_blend:.2f}\") # <-- THIS IS THE NUMBER TO WATCH\n",
    "\n",
    "# --- 8. Create Final Submission ---\n",
    "print(\"Creating final submission file...\")\n",
    "\n",
    "# Convert test (log) predictions to actual cost\n",
    "test_pred_actual_xgb = np.expm1(test_preds_xgb)\n",
    "test_pred_actual_lgbm = np.expm1(test_preds_lgbm)\n",
    "\n",
    "# Blend the test predictions\n",
    "test_pred_actual_blend = 0.5 * test_pred_actual_xgb + 0.5 * test_pred_actual_lgbm\n",
    "test_pred_actual_blend[test_pred_actual_blend < 0] = 0 # Final safety clip\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'Hospital_Id': test_hospital_ids,\n",
    "    'Transport_Cost': test_pred_actual_blend    # <-- This is the fix\n",
    "})\n",
    "\n",
    "sample_submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "submission_df['Transport_Cost'] = submission_df['Transport_Cost'].astype(sample_submission_df['Transport_Cost'].dtype)\n",
    "\n",
    "submission_df.to_csv('submission_v22_ensemble.csv', index=False)\n",
    "\n",
    "print(\"\\n--- DONE ---\")\n",
    "print(\"Submission file 'submission_v22_ensemble.csv' created successfully.\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64570d0-3f9e-40d9-a672-574f47a35ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
